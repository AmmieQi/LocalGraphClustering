{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from localgraphclustering import *\n",
    "except:\n",
    "    # when the package is not installed, import the local version instead. \n",
    "    # the notebook must be placed in the original \"notebooks/\" folder\n",
    "    sys.path.append(\"../\")\n",
    "    from localgraphclustering import * \n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GraphLocal('./datasets/BlogCatalog-dataset/data/edges2.txt','edgelist',' ')\n",
    "\n",
    "# import scipy as sp\n",
    "\n",
    "# I = sp.sparse.csr_matrix(0.005*np.ones((n,n)))\n",
    "\n",
    "# g.adjacency_matrix = g.adjacency_matrix + I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example on how to find all clusters in graph using local graph clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.65324592590332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "start = time.time()\n",
    "# Compute the embeddings X and the pairwise distance matrix Z.\n",
    "embeddings = compute_all_embeddings(g,rho_list=[1.0e-5,1.0e-1],alpha_list=[1.0e-1,2.0e-1],nsamples_from_rho=1,nsamples_from_alpha=1,njobs=6,normalized_objective=False,normalize=False)\n",
    "embeddings_local = normalize_embeddings(g,embeddings, norm_type = 2)\n",
    "# Z = pairwise_distances(X, metric='l2', n_jobs=1)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# # Find the clusters\n",
    "# labels = compute_clusters_given_distance(nclusters=39,Z=Z)\n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = np.loadtxt('./datasets/BlogCatalog-dataset/data/group-edges.txt', dtype = 'int',delimiter=',') - 1\n",
    "\n",
    "Y = np.zeros((g._num_vertices,39))\n",
    "\n",
    "for data in groups:\n",
    "    idx1 = data[0]\n",
    "    idx2 = data[1]\n",
    "    Y[idx1,idx2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edgelist = np.loadtxt('./datasets/BlogCatalog-dataset/data/edges.txt', dtype = 'int',delimiter=',') - 1\n",
    "# np.savetxt(\"./datasets/BlogCatalog-dataset/data/edges2.txt\", edgelist, newline=\"\\n\", fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = embeddings_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=20).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    print(__doc__)\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    from sklearn.datasets import make_multilabel_classification\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.cross_decomposition import CCA\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "#     classif = OneVsRestClassifier(SVC(kernel='linear'))\n",
    "#     classif.fit(X, Y)\n",
    "    \n",
    "    labels = OneVsRestClassifier(SVC(kernel='linear',C=10000,gamma='auto',shrinking=False,tol=1.0e-3,max_iter=20)).fit(X, Y).predict(X) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001939487975174554"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(labels, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = g._num_vertices\n",
    "# from sklearn.cluster import spectral_clustering as spclustering\n",
    "# start = time.time()\n",
    "# labels_spclustering = list(spclustering(g.adjacency_matrix.toarray() + 0.0005*np.ones((n,n)) , n_clusters=39, eigen_solver='arpack'))\n",
    "# end = time.time()\n",
    "# print(end - start)\n",
    "# # for data in groups:\n",
    "# #     idx1 = data[0]\n",
    "# #     idx2 = data[1]\n",
    "# #     group_member[idx1,idx2] = 1\n",
    "# labels_spclustering = np.array(labels_spclustering, dtype=int)\n",
    "\n",
    "# # groups_global = np.zeros((g._num_vertices,40))\n",
    "# # for i in range(g._num_vertices):\n",
    "# #     groups_global[i,labels_spclustering[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import spectral_embedding as spembedding\n",
    "n = g._num_vertices\n",
    "embeddings_global = spembedding(g.adjacency_matrix, n_components=50, eigen_solver='arpack', norm_laplacian=True, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10312, 50)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_global.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = np.loadtxt('./datasets/BlogCatalog-dataset/data/group-edges.txt', dtype = 'int',delimiter=',') - 1\n",
    "\n",
    "Y = np.zeros((g._num_vertices,39))\n",
    "\n",
    "for data in groups:\n",
    "    idx1 = data[0]\n",
    "    idx2 = data[1]\n",
    "    Y[idx1,idx2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = embeddings_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "    print(__doc__)\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    from sklearn.datasets import make_multilabel_classification\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.cross_decomposition import CCA\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "#     classif = OneVsRestClassifier(SVC(kernel='linear'))\n",
    "#     classif.fit(X, Y)\n",
    "    \n",
    "    labels = OneVsRestClassifier(SVC(kernel='linear',C=10000,gamma='auto',shrinking=False,tol=1.0e-3)).fit(X, Y).predict(X) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(labels, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec_emb = np.loadtxt('/Users/kimonfountoulakis/Downloads/snap-master/examples/node2vec/emb/blog.emb', dtype = 'float',delimiter=' ')[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = node2vec_emb\n",
    "\n",
    "groups = np.loadtxt('./datasets/BlogCatalog-dataset/data/group-edges.txt', dtype = 'int',delimiter=',') - 1\n",
    "\n",
    "Y = np.zeros((g._num_vertices,39))\n",
    "\n",
    "for data in groups:\n",
    "    idx1 = data[0]\n",
    "    idx2 = data[1]\n",
    "    Y[idx1,idx2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning:\n",
      "\n",
      "Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    print(__doc__)\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    from sklearn.datasets import make_multilabel_classification\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.cross_decomposition import CCA\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "#     classif = OneVsRestClassifier(SVC(kernel='linear'))\n",
    "#     classif.fit(X, Y)\n",
    "    \n",
    "    labels = OneVsRestClassifier(SVC(kernel='linear',C=10000,gamma='auto',shrinking=False,tol=1.0e-3,max_iter=100)).fit(X, Y).predict(X) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(labels, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
